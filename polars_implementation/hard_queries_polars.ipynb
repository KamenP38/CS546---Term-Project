{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8167e-716c-4e19-8f13-99d8fbcfbef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",base_hard_polars_queries\n",
      "File results_rust_hard_queries_csv/results_rust_plain_hard_125m.txt created/updated successfully!\n",
      "hard,Q1,819.9540143013,8000071592\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "import os\n",
    "import itertools as it\n",
    "\n",
    "indices = ['filename', 'application', 'io_zone', 'redundancy_type']\n",
    "combinations = list(it.combinations(indices, r=2))[:5]\n",
    "\n",
    "# Log results to a file\n",
    "def log_results_to_file(result_file, time_elapsed, memory_usage):\n",
    "    with open(result_file, 'a') as f:\n",
    "        f.write(f\"Times: {time_elapsed}, Memory: {memory_usage}\\n\")\n",
    "    if os.path.exists(result_file):\n",
    "        print(f\"File {result_file} created/updated successfully!\")\n",
    "    else:\n",
    "        print(f\"Error: {result_file} was not created.\")\n",
    "\n",
    "# Base Hard Polars queries without applying custom functions\n",
    "def base_hard_polars_queries(log_dir, result_file):\n",
    "    print(\",base_hard_polars_queries\")\n",
    "    df = pl.scan_csv(log_dir)  # Lazy loading\n",
    "    query_index = 0\n",
    "    for ix, iy in combinations:\n",
    "        for col in ['request_io_size_bytes', 'disk_time']:\n",
    "            query_index += 1\n",
    "            t1 = time.time()\n",
    "\n",
    "            res = (\n",
    "                df.group_by(ix)\n",
    "                .agg([\n",
    "                    pl.col(iy).alias(iy),          # Collect the column as is\n",
    "                    pl.col(col).sum().alias(col)   # Sum aggregation\n",
    "                ])\n",
    "                .explode(iy)                      # Explode the column\n",
    "                .group_by(iy)\n",
    "                .agg([\n",
    "                    pl.col(ix).alias(ix),          # Collect column again as is\n",
    "                    pl.col(col).sum().alias(col)   # Sum aggregation\n",
    "                ])\n",
    "            ).collect(streaming=True)  # Collect to materialize the computation\n",
    "\n",
    "            time_elapsed = time.time() - t1\n",
    "            memory_usage = res.estimated_size()  # Memory usage of the result\n",
    "\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            print(f\"hard,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "# IOMAX Hard Polars queries with LazyFrame\n",
    "def iomax_hard_polars_queries(log_dir, result_file):\n",
    "    print(\",iomax_hard_polars_queries\")\n",
    "    df = pl.scan_csv(log_dir)  # Lazy loading\n",
    "    query_index = 0\n",
    "    for ix, iy in combinations:\n",
    "        for col in ['request_io_size_bytes', 'disk_time']:\n",
    "            query_index += 1\n",
    "            t1 = time.time()\n",
    "            memory_usage = 0\n",
    "            if query_index == 1:\n",
    "                x = df.group_by(indices).agg([\n",
    "                    pl.col(\"request_io_size_bytes\").sum(),\n",
    "                    pl.col(\"disk_time\").sum()\n",
    "                ]).collect(streaming=True)\n",
    "                memory_usage = x.estimated_size()\n",
    "\n",
    "            res = (\n",
    "                x.group_by(ix)\n",
    "                .agg([\n",
    "                    pl.col(iy).alias(iy),\n",
    "                    pl.col(col).sum()\n",
    "                ])\n",
    "                .explode(iy)\n",
    "                .group_by(iy)\n",
    "                .agg([\n",
    "                    pl.col(ix).alias(ix),\n",
    "                    pl.col(col).sum()\n",
    "                ])\n",
    "            )\n",
    "\n",
    "            time_elapsed = time.time() - t1\n",
    "\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            print(f\"hard,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "base_hard_polars_queries(\"../datasets_thesios_io_traces/dataset-125m.csv\", \"results_rust_hard_queries_csv/results_rust_plain_hard_125m.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b9c9e-e7a0-439b-a839-d8b2d3fdfb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
