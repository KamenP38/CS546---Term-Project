{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfec13bd-eb06-41a4-aadc-260a98dc738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",iomax_simple_dask_queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_mempolicy: Function not implemented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q1,542.1808652877808,959176948\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q2,0.027724504470825195,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q3,0.027349472045898438,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q4,0.031377315521240234,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q5,0.027112960815429688,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q6,0.008910655975341797,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q7,0.006523609161376953,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q8,0.005980014801025391,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q9,0.0068323612213134766,0\n",
      "File results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt created/updated successfully!\n",
      "simple,Q10,0.00795602798461914,0\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import numba\n",
    "import cython\n",
    "from time import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import json\n",
    "import resource\n",
    "import numpy as np\n",
    "import cudf\n",
    "import dask_cudf\n",
    "import rmm\n",
    "import pandas as pd\n",
    "\n",
    "from dask.base import normalize_token\n",
    "\n",
    "# Register custom tokenization for cudf.Index\n",
    "@normalize_token.register(cudf.core.index.Index)\n",
    "def normalize_cudf_index(index):\n",
    "    return normalize_token(type(index)), tuple(index.to_pandas().values)\n",
    "\n",
    "# Custom tokenization for cudf.MultiIndex\n",
    "@normalize_token.register(cudf.MultiIndex)\n",
    "def normalize_cudf_multiindex(index):\n",
    "    return normalize_token(type(index)), tuple(index.to_pandas().values)\n",
    "\n",
    "# Log results to a file\n",
    "def log_results_to_file(result_file, time, memory):\n",
    "    with open(result_file, 'a') as f:\n",
    "        f.write(f\"Times: {time}, Memory: {memory}\\n\")\n",
    "    \n",
    "    if os.path.exists(result_file):\n",
    "        print(f\"File {result_file} created/updated successfully!\")\n",
    "    else:\n",
    "        print(f\"Error: {result_file} was not created.\")\n",
    "\n",
    "# Pandas query function\n",
    "def base_simple_cudf_queries(log_dir, result_file):\n",
    "    print(f\",base_simple_pandas_queries\")\n",
    "    df = cudf.read_csv(log_dir)\n",
    "    query_index = 0\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']: \n",
    "            query_index += 1 \n",
    "            t1 = time()\n",
    "            res = df.groupby([ix]).agg({col: 'sum'})\n",
    "            time_elapsed = time() - t1\n",
    "\n",
    "            # Memory usage\n",
    "            memory_usage = res.memory_usage(deep=True).sum()\n",
    "            \n",
    "            # Store the time and memory usage for graphing later   \n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "    \n",
    "# Dask query function\n",
    "def base_simple_dask_queries(log_dir, result_file):\n",
    "    print(f\",base_simple_dask_queries\")\n",
    "    query_index = 0\n",
    "    ddf = dask_cudf.read_csv(f\"{log_dir}\")\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']:\n",
    "            query_index += 1 \n",
    "            t1 = time()\n",
    "            res = ddf.groupby([ix]).agg({col: 'sum'}).compute()\n",
    "            time_elapsed = time() - t1\n",
    "            # print(res)\n",
    "            memory_usage = res.memory_usage(deep=True).sum()\n",
    "\n",
    "            # Store the time and memory usage for graphing later\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "# Pandas IOMAX queries\n",
    "def iomax_simple_cudf_queries(log_dir, result_file):\n",
    "    print(f\",iomax_simple_pandas_queries\")\n",
    "    df = cudf.read_csv(log_dir)\n",
    "    query_index = 0\n",
    "    cols = ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']\n",
    "    agg_dict = {col: 'sum' for col in cols}\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in cols:\n",
    "            query_index += 1\n",
    "            t1 = time()\n",
    "            memory_usage = 0\n",
    "            if query_index == 1:\n",
    "                x = df.groupby(['filename', 'application']).agg(agg_dict)\n",
    "                memory_usage = x.memory_usage(deep=True).sum()\n",
    "            res = x.groupby([ix]).agg({col: 'sum'})\n",
    "            time_elapsed = time() - t1\n",
    "            # print(res)\n",
    "\n",
    "            # Store the time and memory usage for graphing later\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "    \n",
    "# Dask IOMAX queries\n",
    "def iomax_simple_dask_queries(log_dir, result_file):\n",
    "    print(f\",iomax_simple_dask_queries\")\n",
    "    ddf = dask_cudf.read_csv(f\"{log_dir}\")\n",
    "    query_index = 0\n",
    "    cols = ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']\n",
    "    agg_dict = {col: sum for col in cols}\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in cols:\n",
    "            query_index += 1\n",
    "            t1 = time()\n",
    "            memory_usage = 0\n",
    "            if query_index == 1:\n",
    "                x = ddf.groupby(['filename', 'application']).agg(agg_dict).compute()\n",
    "                memory_usage = x.memory_usage(deep=True).sum()\n",
    "            res = x.groupby([ix]).agg({col: 'sum'})\n",
    "            time_elapsed = time() - t1\n",
    "            # print(res)\n",
    "            \n",
    "            # Store the time and memory usage for graphing later\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "iomax_simple_dask_queries('datasets_thesios_io_traces/dataset-125m.csv', 'results_cudf_simple_queries_csv/results_cudf_csv_dask_iomax_simple_125m.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704646a-d646-4231-9b52-2c66112b79c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
