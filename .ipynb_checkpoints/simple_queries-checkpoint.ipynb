{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40bd1e7-f3df-4882-afcf-84f5ce5790cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# The params below are needed only if the researcher wants to run the notebook with papermill\n",
    "# query_function = None\n",
    "# dataset_path = None\n",
    "# result_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e963f499-5bf7-4857-89a3-bb6443f827a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",base_simple_pandas_queries\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q1,0.01770305633544922,2037684\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q2,0.01626443862915039,2037684\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q3,0.017340660095214844,2037684\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q4,0.01747608184814453,2037684\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q5,0.017590999603271484,2037684\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q6,0.010231256484985352,10281\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q7,0.009399652481079102,10281\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q8,0.009655475616455078,10281\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q9,0.009843587875366211,10281\n",
      "File results_simple_queries_csv/results_pandas_plain_simple_200k.txt created/updated successfully!\n",
      "simple,Q10,0.009648323059082031,10281\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import numba\n",
    "import cython\n",
    "from time import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "import json\n",
    "import resource\n",
    "import numpy as np\n",
    "\n",
    "# Function to log results to a file\n",
    "def log_results_to_file(result_file, time, memory):\n",
    "    with open(result_file, 'a') as f:\n",
    "        f.write(f\"Times: {time}, Memory: {memory}\\n\")\n",
    "    \n",
    "    # Check if the file was created\n",
    "    if os.path.exists(result_file):\n",
    "        print(f\"File {result_file} created/updated successfully!\")\n",
    "    else:\n",
    "        print(f\"Error: {result_file} was not created.\")\n",
    "\n",
    "# Query function with memory limit\n",
    "def base_simple_pandas_queries(log_dir, result_file):\n",
    "    print(f\",base_simple_pandas_queries\")\n",
    "    df = pd.read_csv(log_dir)\n",
    "    query_index = 0\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']: \n",
    "            query_index += 1 \n",
    "            t1 = time()\n",
    "            res = df.groupby([ix]).agg({col: 'sum'})\n",
    "            time_elapsed = time() - t1\n",
    "\n",
    "            # Memory usage\n",
    "            memory_usage = res.memory_usage(deep=True).sum()\n",
    "            \n",
    "            # Store the time and memory usage for graphing later   \n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "def base_simple_dask_queries(log_dir, result_file):\n",
    "    print(f\",base_simple_dask_queries\")\n",
    "    query_index = 0\n",
    "    ddf = dd.read_csv(f\"{log_dir}\")\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']:\n",
    "            query_index += 1 \n",
    "            t1 = time()\n",
    "            res = ddf.groupby([ix]).agg({col: 'sum'}).compute()\n",
    "            time_elapsed = time() - t1\n",
    "            memory_usage = res.memory_usage(deep=True).sum()\n",
    "\n",
    "            # Store the time and memory usage for graphing later\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "            \n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "\n",
    "def iomax_simple_pandas_queries(log_dir, result_file):\n",
    "    print(f\",iomax_simple_pandas_queries\")\n",
    "    query_index = 0\n",
    "    df = pd.read_csv(log_dir)\n",
    "    cols = ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']\n",
    "    agg_dict = {col: 'sum' for col in cols}\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in cols:\n",
    "            query_index += 1\n",
    "            t1 = time()\n",
    "            memory_usage = 0\n",
    "            if query_index == 1:\n",
    "                x = df.groupby(['filename', 'application']).agg(agg_dict)\n",
    "                memory_usage = x.memory_usage(deep=True).sum()\n",
    "            x.groupby([ix]).agg({col: 'sum'})\n",
    "            time_elapsed = time() - t1\n",
    "\n",
    "            # Store the time and memory usage for graphing later\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "def iomax_simple_dask_queries(log_dir, result_file):\n",
    "    print(f\",iomax_simple_dask_queries\")\n",
    "    query_index = 0\n",
    "    ddf = dd.read_csv(f\"{log_dir}\")\n",
    "    cols = ['request_io_size_bytes', 'file_offset', 'response_io_size_bytes', 'disk_time', 'simulated_latency']\n",
    "    agg_dict = {col: 'sum' for col in cols}\n",
    "    for ix in ['filename', 'application']:\n",
    "        for col in cols:\n",
    "            query_index += 1\n",
    "            t1 = time()\n",
    "            memory_usage = 0\n",
    "            if query_index == 1:\n",
    "                x = ddf.groupby(['filename', 'application']).agg(agg_dict).compute()\n",
    "                memory_usage = x.memory_usage(deep=True).sum()\n",
    "            x.groupby([ix]).agg({col: 'sum'})\n",
    "            time_elapsed = time() - t1\n",
    "\n",
    "            # Store the time and memory usage for graphing later\n",
    "            log_results_to_file(result_file, time_elapsed, memory_usage)\n",
    "\n",
    "            print(f\"simple,Q{query_index},{time_elapsed},{memory_usage}\")\n",
    "\n",
    "base_simple_pandas_queries(\"datasets_thesios_io_traces/dataset-200k.csv\", \"results_simple_queries_csv/results_pandas_plain_simple_200k.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990aa01-7ebe-400f-811d-fdc784465a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
